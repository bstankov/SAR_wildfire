{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import HDF Modis file to create NDWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import gdal\n",
    "import  sys, shutil\n",
    "import subprocess\n",
    "import os, glob, gdal\n",
    "import datetime\n",
    "import numpy as np\n",
    "# gdal.UseExceptions()\n",
    "#from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Define some methods inside 'proces_HDF()' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class proces_HDF(object):\n",
    "\n",
    "    ''' the module process MODIS hdf file in .../AB_NDWI/hdf folder . First of all, it\n",
    "    extracts the neccessary image bands(2 & 5) , reproject them to geographic and then to 10 tm projection.\n",
    "    After that it creates NDWI image, which is consequently copied to the archive. there are two archives dating since January\n",
    "    2017 onwards, one for path H11V03 and another for H12V03.  finally , all the images in the archive are used\n",
    "    to create a time series mosaic in 'vrt.\n",
    "\n",
    "    '''\n",
    "    def save_vrt2tif(self, output_vrt, tifname):\n",
    "        ''' export virtual file to tiff'''\n",
    "        \n",
    "        gdal_translate = r'C:/P...../gdal_translate.exe'\n",
    "        # save virt as tif\n",
    "        cmd = '-of GTiff'\n",
    "        tran_cmd = ' '.join([gdal_translate, cmd, output_vrt, tifname])\n",
    "        print(\"transcom:\", tran_cmd)\n",
    "        subprocess.Popen(tran_cmd)\n",
    "        # return tifname\n",
    "\n",
    "\n",
    "    def gdalmerge(self,output_vrt, direct_list):\n",
    "        ''' create vrt band to update main file'''\n",
    "        gdalmerge = r'C:/Program Files/GDAL/gdal_merge.py'\n",
    "\n",
    "        cmd = \"-separate -o \" + output_vrt + ' -of GTiff ' + direct_list\n",
    "\n",
    "        fullCmd = ' '.join([gdalmerge, cmd])\n",
    "        print(\"gdalmerge:\", fullCmd)\n",
    "        subprocess.Popen(fullCmd)\n",
    "\n",
    "        print(\"output file is done\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def mkdir(self,dirname, remove=True, chdir=False):\n",
    "        import shutil\n",
    "        \"\"\"create a directory dirnme.  if it iexists     , it is removed by shutil.rmtree\n",
    "        \"\"\"\n",
    "        if os.path.isdir(dirname):\n",
    "            if remove:\n",
    "                shutil.rmtree(dirname)\n",
    "            else:\n",
    "                return False  # did not make new directory\n",
    "        os.mkdir(dirname)\n",
    "\n",
    "        return\n",
    "\n",
    "    def append_date(adatum, date_file):\n",
    "        ''' when we do updates with a new file\n",
    "        it opens a file with dates *.dates and append\n",
    "        a new date to .dates file'''\n",
    "        with open(date_file, 'a') as f:\n",
    "            f.write(adatum  + '\\n')\n",
    "          #  f.write(f'\\n{adatum}') #for python 3\n",
    "    \n",
    "    def save_raster(self,output_name, raster_data, dataset, driver=\"GTiff\"):\n",
    "        \"\"\"\n",
    "        A function to save a 1-band raster using GDAL to the file indicated\n",
    "        by ``output_name``.\n",
    "        Parameters:\n",
    "            output_name: str ........        The output filename, with full path and extension if required\n",
    "        raster_data: array ........        The array that we want to save\n",
    "        dataset: str.............        Filename of a GDAL-friendly dataset that we want to use to\n",
    "            read geotransform & projection information\n",
    "        driver: str .......        A GDAL driver string, like GTiff or HFA.\n",
    "        \"\"\"\n",
    "\n",
    "        # Open the reference dataset\n",
    "        g = gdal.Open(dataset)\n",
    "        # Get the Geotransform vector\n",
    "        geo_transform = g.GetGeoTransform()\n",
    "        x_size = g.RasterXSize  # Raster xsize\n",
    "        y_size = g.RasterYSize  # Raster ysize\n",
    "        srs = g.GetProjectionRef()  # Projection\n",
    "        # Need a driver object. By default, we use GeoTIFF\n",
    "        driver = gdal.GetDriverByName(driver)\n",
    "        dataset_out = driver.Create(output_name, x_size, y_size, 1, gdal.GDT_Float32)\n",
    "        dataset_out.SetGeoTransform(geo_transform)\n",
    "        dataset_out.SetProjection(srs)\n",
    "        dataset_out.GetRasterBand(1).WriteArray(raster_data)\n",
    "        dataset_out = None\n",
    "\n",
    "    def export_bands(self,src, dst):\n",
    "        # cmd = \"gdal_translate.exe -b 2\"\n",
    "        cmd = \"gdal_translate.exe -of MEM -b 2\"\n",
    "        fullCmd = ' '.join([cmd, src, dst])\n",
    "        print(\"com:\", fullCmd)\n",
    "\n",
    "        os.system(fullCmd)\n",
    "        return dst\n",
    "\n",
    "    def extport2sinus(self,hdf_layer, dst_singrd):\n",
    "        # gdalwarp - of GTiff HDF4_EOS: EOS_GRID:\"MOD09A1.A2020001.h11v03.006.2020010223355.hdf\": MOD_Grid_500m_Surface_Reflectance:sur_refl_b02 b2.tif'\n",
    "        # cmd = 'gdalwarp.exe -of GTiff -tps -t_srs \"EPSG:4326\" -ts 2400 2400'\n",
    "        cmd = 'gdalwarp.exe -of GTiff '\n",
    "        # cmd = \"gdal_translate.exe -of MEM -b 2\"\n",
    "        fullCmd = ' '.join([cmd, hdf_layer, dst_singrd])\n",
    "        print(\"com:\", fullCmd)\n",
    "        os.system(fullCmd)\n",
    "        return dst_singrd\n",
    "\n",
    "    def sin_wgs84(self,input_sin, out84):\n",
    "        # gdalwarp -of GTiff -t_srs \"EPSG:4326\" -ts 2400 2400 \"b2.tif\" \"b2_wgs84.tif\"\n",
    "        cmd = 'gdalwarp.exe -of GTiff -t_srs \"EPSG:4326\" -ts 2400 2400'\n",
    "        fullCmd = ' '.join([cmd, input_sin, out84])\n",
    "        print(\"com:\", fullCmd)\n",
    "        os.system(fullCmd)\n",
    "        return out84\n",
    "\n",
    "    def wgs84_epsg3400(self,out84, out_10tm):\n",
    "\n",
    "        ##gdalwarp -t_srs EPSG:3400 -tr 500 500 -te 152000 5853000 860600 6660000 b2_wgs84.tif b2_wgs84_10tm_sub.tif\n",
    "        cmd = 'gdalwarp.exe -t_srs EPSG:3400 -tr 500 500 -te 152000 5853000 860600 6660000'\n",
    "        fullCmd = ' '.join([cmd, out84, out_10tm])\n",
    "        print(\"com:\", fullCmd)\n",
    "        os.system(fullCmd)\n",
    "        return out_10tm\n",
    "\n",
    "    def run_gridClip(self,Xmin, Ymin, Xmax, Ymax, src, dst):\n",
    "        cmd = \"gdalwarp.exe -t_srs EPSG:3400 -tr 500 500 -te\"\n",
    "        # gdal_Warp = 'C:/Program Files/GDAL/gdalwarp.exe'\n",
    "\n",
    "        # fullCmd = ' '.join([gdal_Warp, cmd, str(Xmin), str(Ymin), str(Xmax), str( Ymax), \"-dstnodata -9999.0 \", src, dst])\n",
    "        fullCmd = ' '.join([cmd, str(Xmin), str(Ymin), str(Xmax), str(Ymax), \"-dstnodata -9999.0 \", src, dst])\n",
    "        print(\"com:\", fullCmd)\n",
    "\n",
    "        os.system(fullCmd)\n",
    "        return dst\n",
    "\n",
    "    def getDate_from_hdfJD(self,file):\n",
    "        ''' convert ordinal day to a date and create name for a file'''\n",
    "        # import datetime\n",
    "        file1 = file.split('_')[1][1:]\n",
    "        jd = file1[2:]\n",
    "        a = datetime.datetime.strptime(str(jd), '%y%j').date()\n",
    "        adate = \"A\" + file1 + '_' + a.strftime('%Y%m%d')\n",
    "        return adate\n",
    "\n",
    "    def youCanQuoteMe(self,item):\n",
    "        return \"\\\"\" + item + \"\\\"\"\n",
    "\n",
    "    # ************************\n",
    "    def run_proc_HDF(self, path):\n",
    "\n",
    "        hdf_folder = path +'/hdf'\n",
    "        os.chdir(hdf_folder)\n",
    "        cur_folder =path + '/current'\n",
    "\n",
    "        outdir = hdf_folder + '/out'\n",
    "        print(\"createubg outdir: \",outdir)\n",
    "        self.mkdir(outdir)\n",
    "        path_10tm = hdf_folder + '/10tm'\n",
    "        print(\"createing path 10tm: \", path_10tm)\n",
    "        self.mkdir(path_10tm)\n",
    "        themain = path + '/main'\n",
    "        #self.mkdir(themain)\n",
    "        hdf_List = glob.glob(\"*.hdf\")\n",
    "        print(\"hdflst:\",hdf_List)\n",
    "        gdal.UseExceptions()\n",
    "        x = 0\n",
    "        for afile in hdf_List:\n",
    "       \n",
    "            filename=afile        \n",
    "            g = gdal.Open(filename)\n",
    "            # g should now be a GDAL dataset, but if the file isn't found\n",
    "            # g will be none. Let's test this:\n",
    "            if g is None:\n",
    "                print (\"Problem opening file %s!\" % filename)\n",
    "            else:\n",
    "                print (\"File %s opened fine\" % filename)\n",
    "\n",
    "            subdatasets = g.GetSubDatasets()\n",
    "            for fname, name in subdatasets:\n",
    "                print(name)\n",
    "                print (\"\\t\", fname)\n",
    "\n",
    "            # Let's create a list with the selected layer names\n",
    "            selected_layers = [  \"sur_refl_b02\", \"sur_refl_b05\" ]\n",
    "\n",
    "            # We will store the data in a dictionary\n",
    "            # Initialise an empty dictionary\n",
    "            data = {}\n",
    "\n",
    "            file_template = 'HDF4_EOS:EOS_GRID:\"%s\":MOD_Grid_500m_Surface_Reflectance:%s'\n",
    "\n",
    "            for i, layer in enumerate ( selected_layers ):\n",
    "                this_file = file_template % ( filename, layer )\n",
    "                print(\"thisfile: \",this_file)\n",
    "                print( \"Opening Layer %d: %s\" % (i+1, this_file ))\n",
    "                g = gdal.Open ( this_file )\n",
    "\n",
    "                if g is None:\n",
    "                    raise IOError\n",
    "                data[layer] = g.ReadAsArray()\n",
    "                print (\"\\t>>> Read %s!\" % layer)\n",
    "                print(\"proecessing: layer: i: \",i)\n",
    "\n",
    "                parts = this_file.split(':')\n",
    "                ime = parts[2][1:-5] + '_' + parts[4]\n",
    "                dst_singrd =ime.replace('.', '_')+'.tif'\n",
    "                print(\"input 4 extport2sinu\", this_file, dst_singrd)\n",
    "                #run function\n",
    "                self.extport2sinus(this_file, dst_singrd)     #ISKLJUCI/UKLJUCI\n",
    "               #\n",
    "               # # run sinus to geogrpahic\n",
    "                out_84 = dst_singrd[:-4]+'_wgs84.tif'\n",
    "                print(\"Out_84 ime:\",out_84)\n",
    "               #  print(\"input 4 sin2wgs84\",dst_singrd, out84)\n",
    "                self.sin_wgs84(dst_singrd, out_84)    #ISKLJUCI/UKLJUCI\n",
    "               #  #\n",
    "                # # run geographic to 10 TM\n",
    "\n",
    "                out_10tm = out_84.replace('wgs84','10tm')\n",
    "                out_10tm_ = os.path.join( path_10tm ,out_10tm)\n",
    "                print(\"input 4 sin2wgs84\", dst_singrd, out_10tm)\n",
    "\n",
    "                self.wgs84_epsg3400(out_84, out_10tm_)   #ISKLJUCI/UKLJUCI\n",
    "\n",
    "                oname = self.getDate_from_hdfJD(out_10tm)\n",
    "                print(\"oname????\", oname)\n",
    "\n",
    "\n",
    "            try:\n",
    "                def remove_nan(raster_in):\n",
    "                    \"\"\"Overwrite NaNs with column value interpolations.\"\"\"\n",
    "                    # overwrite 'inf' values with column mean\n",
    "                    raster_no_INF = interpolate_infs(raster_in)\n",
    "                    # get column means\n",
    "                    raster_no_INF_CM = np.nanmean(raster_no_INF, axis=0)\n",
    "                    # find indexes where we need replace 'nan' values with col means\n",
    "                    inds = np.where(np.isnan(raster_no_INF))\n",
    "                    #  place column means in the indices. align the arrays using take\n",
    "                    raster_no_INF[inds] = np.take(raster_no_INF_CM, inds[1])\n",
    "\n",
    "                    return raster_no_INF\n",
    "\n",
    "                def interpolate_infs(X):\n",
    "\n",
    "                    \"\"\"Overwrite INFs with column value interpolations.\"\"\"\n",
    "                    for j in range(X.shape[1]):\n",
    "                        # mask_j = np.isnan(X[:,j])   #for nans\n",
    "                        mask_j = np.isinf(X[:, j])  # for infns\n",
    "                        X[mask_j, j] = np.interp(np.flatnonzero(mask_j), np.flatnonzero(~mask_j), X[~mask_j, j])\n",
    "                    return X\n",
    "\n",
    "                files2READ = glob.glob(path_10tm + '/*.tif')\n",
    "                #files2READ = glob.glob(path_10tm +'/*.tif')\n",
    "                print(\"files to read:\",files2READ)\n",
    "                #files_string = \" \".join(files2READ)\n",
    "                b2_ds = gdal.Open(files2READ[0], gdal.GA_ReadOnly)\n",
    "            #\n",
    "                if b2_ds is None:\n",
    "                    print(\"no data set\")\n",
    "                #get projection info\n",
    "                ds_proj = b2_ds.GetProjection()\n",
    "                geot = b2_ds.GetGeoTransform()\n",
    "                width = b2_ds.RasterXSize\n",
    "                height = b2_ds.RasterYSize\n",
    "                bands = b2_ds.RasterCount\n",
    "                print(width, height,bands)\n",
    "                print(ds_proj)\n",
    "                # Metadata for the raster dataset\n",
    "                b2_ds.GetMetadata()\n",
    "                #open band 5\n",
    "                b5_ds = gdal.Open(files2READ[1], gdal.GA_ReadOnly)\n",
    "                #\n",
    "                if b5_ds is None:\n",
    "                    print(\"no data set\")\n",
    "\n",
    "                np.seterr(divide='ignore',invalid = 'ignore')\n",
    "                B2 = b2_ds.GetRasterBand(1)\n",
    "                #get no data value\n",
    "                nodata = B2.GetNoDataValue()\n",
    "                B2_ar = np.array(B2.ReadAsArray(),dtype = float)\n",
    "                #clean for 'nan' and 'inf' data\n",
    "\n",
    "                interpolate_infs(B2_ar)   #remove infs values\n",
    "                B2_clean = remove_nan(B2_ar)    #remove nans\n",
    "\n",
    "                B5 = b5_ds.GetRasterBand(1)\n",
    "                B5_ar= np.array(B5.ReadAsArray(),dtype = float)\n",
    "                # clean for 'nan' and 'inf' data\n",
    "\n",
    "                B5_ar = interpolate_infs(B5_ar)  # remove infs values\n",
    "                B5_clean = remove_nan(B5_ar)  # remove nans\n",
    "                ndwi = (B2_ar-B5_ar)/(B2_ar+B5_ar)*10000\n",
    "                #create ndwi with dealing with NODATA\n",
    "                #ndwi = np.where(B2_clean == nodata, nodata,  (B2_clean-B5_clean)/(B2_clean+B5_clean)*10000)\n",
    "                print(\"NDWI:\", ndwi[0][0])\n",
    "                outdriver = gdal.GetDriverByName(\"GTiff\")\n",
    "                #output_name =os.path.join( outdir, os.path.basename(files2READ[0]))\n",
    "                output_name = os.path.join(outdir, oname+ '_ndwi.tif')\n",
    "\n",
    "               # out_ndwi = outdriver.Create(output_name, width,height, 1, gdal.GDT_Float32)\n",
    "                #integer output\n",
    "                out_ndwi = outdriver.Create(output_name, width, height, 1, gdal.GDT_Float32)\n",
    "\n",
    "                #save_raster(output_name,ndwi, tifname1, driver=\"GTiff\")\n",
    "                out_ndwi.GetRasterBand(1).WriteArray(ndwi)\n",
    "                    # #set space\n",
    "                out_ndwi.SetGeoTransform(geot)\n",
    "                   # #set projection\n",
    "                out_ndwi.SetProjection(ds_proj)\n",
    "                #ensure that the data have been written to disk instead of only cached in memory,\n",
    "                out_ndwi.FlushCache()\n",
    "                #makes it easier for some software to display it nicely\n",
    "                #Compute statistics if needed\n",
    "                if out_ndwi.GetRasterBand(1).GetMinimum() is None or out_ndwi.GetRasterBand(1).GetMaximum() is None:\n",
    "                    out_ndwi.GetRasterBand(1).ComputeStatistics(False)\n",
    "                #build overview layers for the dataset\n",
    "                out_ndwi.BuildOverviews('average', [2, 4, 8, 16, 32])\n",
    "                 # Fetch metadata for the band\n",
    "                out_ndwi.GetRasterBand(1).GetMetadata()\n",
    "\n",
    "                # Print only selected metadata:\n",
    "                print(\"[ NO DATA VALUE ] = \", out_ndwi.GetRasterBand(1).GetNoDataValue())  # none\n",
    "                print(\"[ MIN ] = \", out_ndwi.GetRasterBand(1).GetMinimum())\n",
    "                print(\"[ MAX ] = \", out_ndwi.GetRasterBand(1).GetMaximum())\n",
    "\n",
    "                b2_ds = None\n",
    "                b5_ds = None\n",
    "                g = None\n",
    "\n",
    "                # #GET DATE FROM CURRENT IMAGE AND UPDATE *.DATES FILE\n",
    "                # #***************************\n",
    "                # 'namef' variable goes into name of the output files\n",
    "\n",
    "                namef = oname.split('_')[1]\n",
    "                print(\"namef:\", namef)\n",
    "                date_file = 'C:/_LOCALdata/_PROJECTS_hist/prj_2020/AB_NDWI/ARCHIVE.dates'\n",
    "\n",
    "                ###ISLJUJCI/  UKLJUCI\n",
    "               # self.append_date(namef, date_file)\n",
    "                with open(date_file, 'a') as f:\n",
    "\n",
    "                    f.write(namef + '\\n')\n",
    "                    #f.write(f'\\n{namef}')  #for python 3\n",
    "\n",
    "                #clear the folder\n",
    "                files = glob.glob(os.getcwd() +'/*.tif')\n",
    "                for f in files:\n",
    "                    os.remove(f)\n",
    "                files10 = glob.glob(os.getcwd() + '/10tm/*.tif')\n",
    "                for f10 in files10:\n",
    "                    os.remove(f10)\n",
    "                os.rmdir(path_10tm)\n",
    "\n",
    "\n",
    "            except RuntimeError:\n",
    "                print (\"Exception: \", err)\n",
    "                exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # create object\n",
    "    def vrt_mosac(direct, output_vrt):\n",
    "        ''' create vrt band to update main file'''\n",
    "        buildvrt = r'C:/...L/gdalbuildvrt.exe'\n",
    "\n",
    "        cmd = \"-separate \" + output_vrt + ' ' + direct + '/*.tif'\n",
    "        # cmd = output_vrt + ' ' + dir\n",
    "        fullCmd = ' '.join([buildvrt, cmd])\n",
    "        print(\"fullcmd:\", fullCmd)\n",
    "        subprocess.Popen(fullCmd)\n",
    "\n",
    "        print(\"output file is done\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    #path = 'C:/folderNaem/prj_2020/NDWI/data_in'\n",
    "    path = 'C:/_olderNaemist/prj_2020/AB_NDWI'\n",
    "\n",
    "    obj = proces_HDF()\n",
    "    #go in to path folder\n",
    "    obj.run_proc_HDF(path)\n",
    "\n",
    "    #Now we have current NDWI in 'out' folder , we copy new NDWI into archive and create *.vrt mosaic\n",
    "    file_list = glob.glob(path + '/hdf/out/*.tif')\n",
    "    output = path + '/ARCHIVE/' + os.path.basename(file_list[0])\n",
    "    shutil.copy2(file_list[0], output)\n",
    "    name = os.path.basename(file_list[0])\n",
    "\n",
    "    # 1.c)  get current Julian day to be part of the name for timeseries\n",
    "    # # *********************************************************************\n",
    "    today = datetime.datetime.now()\n",
    "    day_of_year = (today - datetime.datetime(today.year, 1, 1)).days + 1\n",
    "    # day of year goes into name of the output\n",
    "\n",
    "    #create virtual mosaic of all ndwi images\n",
    "    ouput_vrt = path + '/main' +  '/main_NDWI_' + str(day_of_year) + '_.vrt'\n",
    "    archive = os.path.join(path + '/ARCHIVE')\n",
    "    # virtual mosaic is created from a folder of files\n",
    "    print(\"bilding mosaic...\")\n",
    "    vrt_mosac(archive, ouput_vrt ) \n",
    "    #remove files from folder with new NDWI -'out'\n",
    "    fil =  glob.glob(path + '/hdf/out/*.tif')\n",
    "    for afile in fil:\n",
    "        os.remove(afile)\n",
    "\n",
    "    obj = None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
